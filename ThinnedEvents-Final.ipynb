{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook provides implementation of an inference technique for inhomogenuous poisson process using thinned events. For more details, please refer to Adams et al \"Tractable Nonparametric Bayesian Inference in Poisson Processes with Gaussian Process Intensities\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import GPy\n",
    "import edward as ed\n",
    "from kern import RBF, Periodic\n",
    "import tensorflow as tf\n",
    "from datasets import build_toy_dataset1, build_toy_dataset2\n",
    "from matplotlib import pyplot as plt\n",
    "from thinnedEvents import ThinnedEventsSolver, ThinnedEventsSampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulate data using Intensity function\n",
    "\n",
    "> $$ \\lambda_1(s) = 2 \\exp\\{-s/15\\} + \\exp\\{-((s-25)/10)^2\\}$$\n",
    "> $$ \\lambda_2(s) = 5 \\sin(s^2) + 6$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD8CAYAAABw1c+bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fda2c16dd10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "events, Z, N, rate, measure = build_toy_dataset1()\n",
    "print(N)\n",
    "kern = RBF(input_dim=1, lengthscale=1)\n",
    "plt.scatter(events, Z)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = ThinnedEventsSampler(events, kern, measure, rate)\n",
    "x_K, y_K, x_M, y_M = sampler.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference\n",
    "\n",
    "The inference is done via a three step sampling procedure. Here, we consider that the Poisson data is generated from a random intensity function drawn from a gaussian process prior. The model is constructed by adding latent variables such as number of thinned events, their locations and the function values at those events. Finally, we run inference over the posterior of the function values given the latent variables.\n",
    "\n",
    "Construct ThinnedEventsSolver object which takes the event locations and the covariance kernel as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solver = ThinnedEventsSolver(events, kern, measure, rate)\n",
    "S,G = solver.solve(n_iter = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(S, rate / (1 + np.exp(-G)))\n",
    "plt.ylim((0, rate))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_toy_dataset1():\n",
    "    rate = 2\n",
    "    measure = 50\n",
    "    N = np.random.poisson(measure * rate)\n",
    "    S = np.expand_dims(np.sort(np.linspace(0, measure, N)), axis = 1)\n",
    "    Z = 2*np.exp(-S/15) + np.exp(-((S-25)/10)**2)\n",
    "    print(N)\n",
    "    return S, Z, N, rate, measure\n",
    "\n",
    "def build_toy_dataset2():\n",
    "    rate = 12\n",
    "    measure = 5\n",
    "    N = np.random.poisson(measure * rate)\n",
    "    S = np.expand_dims(np.sort(np.linspace(0, measure, N)), axis = 1)\n",
    "    Z = 5 * np.sin(S**2) + 6\n",
    "    print(N)\n",
    "    return S, Z, N, rate, measure\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate and plot data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = GPy.kern.PeriodicExponential(input_dim=1, period=5, variance=3)\n",
    "S, Z, N, rate, measure = build_toy_dataset2()\n",
    "plt.scatter(S, Z)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thinning events to keep data points consistent with the intensity function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = np.random.uniform(0, 1, N)\n",
    "V = (Z / rate).flatten()\n",
    "G = np.random.multivariate_normal(np.zeros((S.shape[0])), k.K(S, S))\n",
    "accept = np.where(R < (1 / (1 + np.exp(-G))))\n",
    "S_k  = np.take(S, accept, axis=0).reshape(-1,1)\n",
    "Z_k  = np.take(Z, accept, axis=0).reshape(-1)\n",
    "#G_k = np.log(Z_k / (rate - Z_k)).reshape(-1)\n",
    "G_k = np.take(G, accept, axis=0).reshape(-1)#random.multivariate_normal(np.zeros((S_k.shape[0])), k.K(S_k,S_k))\n",
    "#X = k.K(S_k, S_k)\n",
    "plt.scatter(S_k, Z_k)\n",
    "plt.show()\n",
    "K = S_k.shape[0]\n",
    "print(N,K)\n",
    "plt.ylim((0,10))\n",
    "plt.scatter(S_k, rate/(1+np.exp(-G_k)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prior_loss = 0.5 * np.matmul(np.expand_dims(G_k, axis=0), np.matmul(np.linalg.inv(X + 1e-6*np.eye(K)), np.expand_dims(G_k, axis=1)))\n",
    "prior_loss = 0.5 * np.matmul(np.expand_dims(G_k, axis=0), np.expand_dims(G_k, axis=1))\n",
    "like_loss = np.sum(np.log(np.ones(K) + np.exp(-G_k)))\n",
    "print(like_loss)\n",
    "#likelihood_loss = tf.reduce_sum(tf.log(tf.ones([K]) + tf.exp(-tf.slice(F, [0], [K]))))\n",
    "#likelihood_loss += tf.reduce_sum(tf.log(tf.ones([M]) + tf.exp(tf.slice(F, [K], [M]))))    \n",
    "loss = prior_loss + like_loss\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conditional for Gaussian process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conditional(x_new, x, y, k):\n",
    "\n",
    "    B = k.K(x_new, x)\n",
    "    C = k.K(x,x)\n",
    "    A = k.K(x_new, x_new)\n",
    "    N = len(C)\n",
    "    mu = B.dot(np.linalg.inv(C + 1e-6*np.eye(N))).dot(y)\n",
    "    sigma = A - B.dot(np.linalg.inv(C + 1e-6*np.eye(N)).dot(B.T))\n",
    "    return(mu.squeeze(), sigma.squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update(x_K, y_K, x_M, y_M):\n",
    "   \n",
    "    bern_p = 0.5\n",
    "    K = len(x_K)\n",
    "    \n",
    "    ### Sampling number of thinned events\n",
    "    for i in range(10):\n",
    "        b = bernoulli.rvs(bern_p, size=1)     # Sample from a bernoulli\n",
    "        M = len(x_M)\n",
    "        if b==1:\n",
    "            x_new = np.random.uniform(low=0.0, high = measure, size=(1,1))   # Sample uniformly from the region\n",
    "            \n",
    "            mu_new, sigma_new = conditional(x_new, np.concatenate((x_K,x_M), axis=0), np.concatenate((y_K, y_M), axis=0), k)\n",
    "            y_new = np.random.normal(loc=mu_new, scale=np.sqrt(sigma_new))\n",
    "            \n",
    "            ## Calculate insertion ratio\n",
    "            ratio = np.log(rate * measure)\n",
    "            ratio -= np.log(M + 1)\n",
    "            ratio -= np.log(1 + np.exp(y_new))\n",
    "            a = np.random.uniform(0, 1)\n",
    "            \n",
    "            if np.log(a) < ratio:\n",
    "                x_M = np.concatenate((x_M, x_new), axis=0)\n",
    "                y_M = np.concatenate((y_M, np.expand_dims(y_new, axis=1)))\n",
    "        \n",
    "        \n",
    "        elif M>0:\n",
    "            c = np.random.choice(M, 1)[0]    # Uniformly choose an event to delete\n",
    "            \n",
    "            ## Calculate deletion ratio\n",
    "            ratio = np.log(M)\n",
    "            ratio += np.log(1 + np.exp(y_M[c]))\n",
    "            ratio -= np.log(rate * measure)\n",
    "            a = np.random.uniform(0, 1)\n",
    "            \n",
    "            if np.log(a) < ratio:\n",
    "                x_M = np.delete(x_M, c, 0)\n",
    "                y_M = np.delete(y_M, c)\n",
    "\n",
    "\n",
    "    ## Sampling the location of thinned events\n",
    "\n",
    "    for i in range(len(x_M)):   # Use enumerate\n",
    "\n",
    "        x_new = np.random.normal(loc=x_M[i], scale=np.sqrt(1.0*measure/100.0), size=(1,1))#np.random.uniform(low=0.0, high=measure, size=(1,1))    # Sample a new data point\n",
    "        mu_new, sigma_new = conditional(x_new, np.concatenate((x_K,np.delete(x_M,i,axis=0)), axis=0), np.concatenate((y_K, np.delete(y_M,i,axis=0)), axis=0), k)\n",
    "        y_new = np.random.normal(loc=mu_new, scale=np.sqrt(sigma_new))\n",
    "        \n",
    "        # Calculate the acceptance ratio\n",
    "        ratio = np.log(1 + np.exp(y_M[i]))\n",
    "        ratio -= np.log(1 + np.exp(y_new))\n",
    "\n",
    "        a = np.random.uniform(0, 1)\n",
    "        if np.log(a) < ratio:\n",
    "            x_M[i] = x_new\n",
    "            y_M[i] = y_new\n",
    "            \n",
    "    \n",
    "    S = np.concatenate((x_K, x_M), axis=0)\n",
    "    G = np.concatenate((y_K, y_M), axis=0)\n",
    "    N = S.shape[0]       # Number of data points K+M\n",
    "    D = S.shape[1]       # Dimension of the space\n",
    "    M = len(x_M)\n",
    "    C = k.K(S,S).astype(np.float32)\n",
    "    #chol = np.linalg.cholesky(np.linalg.inv(C + 1e-6 * np.eye(N)))\n",
    "    #G = np.matmul(chol, G)\n",
    "    ## Learn function values via gradient optimization\n",
    "    X = tf.constant(C)\n",
    "    F = tf.Variable(G, name=\"FunctionVal\", dtype=tf.float32)\n",
    "    prior_loss = 0.5 * tf.matmul(tf.expand_dims(F, axis=0), tf.matmul(tf.matrix_inverse(X + 1e-6*tf.eye(N)), tf.expand_dims(F, axis=1)))\n",
    "    #prior_loss = 0.5 * tf.matmul(tf.expand_dims(F, axis=0), tf.expand_dims(F, axis=1))\n",
    "    prior_loss = tf.squeeze(prior_loss)\n",
    "    likelihood_loss = tf.reduce_sum(tf.log(tf.ones([K]) + tf.exp(-tf.slice(F, [0], [K]))))\n",
    "    likelihood_loss += tf.reduce_sum(tf.log(tf.ones([M]) + tf.exp(tf.slice(F, [K], [M]))))    \n",
    "    loss = prior_loss + likelihood_loss\n",
    "    train_op = tf.train.AdadeltaOptimizer(0.01,0.95,1e-5).minimize(loss)\n",
    "    init_OP = tf.global_variables_initializer()\n",
    "    max_it = 500\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init_OP)\n",
    "        for i in range(max_it):\n",
    "            err, _ = sess.run([loss, train_op])\n",
    "        val = sess.run(F)\n",
    "    print(err)\n",
    "    y_K, y_M = val[:K], val[K:]\n",
    "    return x_K, y_K, x_M, y_M, val, err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iter = 30\n",
    "x_K, y_K = S_k, G_k\n",
    "x_M, y_M = np.empty((0,1)), np.empty((0))\n",
    "errors = []     # List to maintain loss value at each iteration\n",
    "for n in range(n_iter):\n",
    "    \n",
    "    x_K, y_K, x_M, y_M, val, err = update(x_K, y_K, x_M, y_M)\n",
    "    print(x_M.shape)\n",
    "    errors.append(err)\n",
    "\n",
    "S = np.concatenate((x_K,x_M), axis=0)\n",
    "plt.plot(np.arange(n_iter), errors)\n",
    "#plt.scatter(S, rate / (1 + np.exp(-val)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(S.shape, Z.shape)\n",
    "                     \n",
    "plt.xlim((0,5))\n",
    "plt.scatter(S_k, Z_k)\n",
    "plt.show()\n",
    "plt.ylim((0,10))\n",
    "plt.xlim((0,5))\n",
    "plt.scatter(S, rate / (1 + np.exp(-val)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End of Relevant Code\n",
    "\n",
    "\n",
    "# Junk Code below this cell. Please do not read."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S = np.concatenate((x_K,x_M), axis=0)\n",
    "print(x_K.shape, val.shape)\n",
    "plt.scatter(x_K, rate / (1 + np.exp(-val[:K])))\n",
    "plt.show()\n",
    "print(k.K(S, S))\n",
    "print(C)\n",
    "print(rate, measure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(x_K), len(x_M))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "K = len(x_K)\n",
    "M = len(x_M)\n",
    "print(N)\n",
    "print(K,M)\n",
    "plt.scatter(S, G)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.constant(C)\n",
    "F = tf.Variable(G, name=\"FunctionVal\", dtype=tf.float32)\n",
    "\n",
    "prior_loss = 0.5*tf.matmul(tf.expand_dims(F, axis=0), tf.matmul(tf.matrix_inverse(X + 1e-6*tf.eye(N)), tf.expand_dims(F, axis=1)))\n",
    "prior_loss = tf.squeeze(prior_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf.ones(shape=[K])\n",
    "#tf.slice(F, [0], [K])\n",
    "likelihood_loss = tf.reduce_sum(tf.log(tf.ones([K]) + tf.exp(-tf.slice(F, [0], [K]))))\n",
    "likelihood_loss += tf.reduce_sum(tf.log(tf.ones([M]) + tf.exp(tf.slice(F, [K], [M]))))    \n",
    "loss = prior_loss + likelihood_loss\n",
    "train_op = tf.train.AdadeltaOptimizer(0.01, 0.95, 1e-5).minimize(loss)\n",
    "#train_op = tf.train.GradientDescentOptimizer(1e-7).minimize(loss)\n",
    "init_OP = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init_OP)\n",
    "    l = sess.run(loss)\n",
    "    print(l)\n",
    "    for i in range(100):\n",
    "        #print(sess.run(tf.gradients(loss, F)))\n",
    "        sess.run(train_op)\n",
    "        l = sess.run(loss)\n",
    "        print(l)\n",
    "        \n",
    "    val = sess.run(F)\n",
    "    \n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(S, val)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
